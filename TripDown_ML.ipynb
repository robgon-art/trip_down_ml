{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/trip_down_ml/blob/main/TripDown_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Upg03_f_XRt"
      },
      "outputs": [],
      "source": [
        "!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5H2IyZ0AMCD"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Read images, get face positions and embeddings\n",
        "def get_face_data(image_path):\n",
        "    image = face_recognition.load_image_file(image_path)\n",
        "\n",
        "    # Convert the numpy array image to a PIL Image object\n",
        "    img = Image.fromarray(image)\n",
        "    # Get the current size\n",
        "    width, height = img.size\n",
        "    # Determine the scaling factor\n",
        "    max_dimension = max(width, height)\n",
        "    scaling_factor = 1024 / max_dimension\n",
        "    # Calculate the new size\n",
        "    new_width = int(width * scaling_factor)\n",
        "    new_height = int(height * scaling_factor)\n",
        "    # Resize the image\n",
        "    resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
        "    # Convert the PIL Image back to a numpy array if needed\n",
        "    resized_image_array = np.array(resized_img)\n",
        "\n",
        "    face_locations = face_recognition.face_locations(resized_image_array, model=\"cnn\")\n",
        "\n",
        "    # Scale the face locations back up to the original image size\n",
        "    scaled_face_locations = []\n",
        "    for location in face_locations:\n",
        "        top, right, bottom, left = location\n",
        "        scaled_location = (\n",
        "            int(top / scaling_factor),\n",
        "            int(right / scaling_factor),\n",
        "            int(bottom / scaling_factor),\n",
        "            int(left / scaling_factor)\n",
        "        )\n",
        "        scaled_face_locations.append(scaled_location)\n",
        "\n",
        "    # Generate encodings from the positions in the full-sized image\n",
        "    encodings = face_recognition.face_encodings(image, known_face_locations=scaled_face_locations)\n",
        "    return scaled_face_locations, encodings\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/photos/Jen and Rob backyard.jpg\"\n",
        "positions, encs = get_face_data(file_path)\n",
        "print(positions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPMCA_UTA_jg"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as display_Image\n",
        "\n",
        "# Display the image\n",
        "display_Image(filename=file_path, width=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKeRXVj9B2Eu"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display as display_function\n",
        "\n",
        "# Assuming `file_path` is a variable containing the path to your image\n",
        "# # And `positions` is a list of tuples with the face locations in the format (top, right, bottom, left)\n",
        "\n",
        "# Load the image\n",
        "image = Image.open(image_1_path)\n",
        "\n",
        "# Loop through the face positions and display each cropped face\n",
        "for position in face_locations_1:\n",
        "    print(position)\n",
        "    # Crop the image to the face location\n",
        "    top, right, bottom, left = position\n",
        "    face_image = image.crop((left, top, right, bottom))\n",
        "\n",
        "    # Resize the face image\n",
        "    face_image = face_image.resize((256, 256), Image.LANCZOS )\n",
        "\n",
        "    # Display the face image\n",
        "    display_function(face_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xlaofO6hOF9"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "file_paths = glob.glob(\"/content/drive/MyDrive/photos/*\")\n",
        "file_paths.sort()\n",
        "print(len(file_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o1FORs40yMh"
      },
      "outputs": [],
      "source": [
        "# Step 2: Store in DataFrame\n",
        "df = pd.DataFrame(columns=['file_path', 'position', 'encoding_index'])\n",
        "embeddings = []\n",
        "\n",
        "for i, file_path in enumerate(file_paths):\n",
        "    if i %10 == 0:\n",
        "      print(i)\n",
        "    positions, encs = get_face_data(file_path)\n",
        "    for pos, enc in zip(positions, encs):\n",
        "        new_row = pd.DataFrame({'file_path': [file_path],\n",
        "                                'position': [pos],\n",
        "                                'encoding_index': [len(embeddings)],\n",
        "                                'label': [None]  # Initialize the label as None or a placeholder\n",
        "                                })\n",
        "\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "        embeddings.append(enc)\n",
        "\n",
        "# Convert embeddings to a NumPy array\n",
        "embeddings = np.array(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "DtctdqlSI0Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WfDkn6Mk1LT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Step 1: Select 20 random samples\n",
        "sample_df = df.sample(20)\n",
        "\n",
        "# Step 2: Create a 4x5 grid for thumbnails\n",
        "fig, axes = plt.subplots(4, 5, figsize=(6, 5))\n",
        "\n",
        "# Flatten the axes array for easy indexing\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Step 3: Load images, resize, crop, and display\n",
        "for i, (idx, row) in enumerate(sample_df.iterrows()):\n",
        "    # Load the image\n",
        "    image = Image.open(row['file_path'])\n",
        "\n",
        "    # Crop to the face location\n",
        "    position = row['position']\n",
        "    top, right, bottom, left = position\n",
        "    face_image = image.crop((left, top, right, bottom))\n",
        "\n",
        "    # Resize to thumbnail (preserving aspect ratio)\n",
        "    face_image.thumbnail((64, 64))\n",
        "\n",
        "    # Display the thumbnail\n",
        "    axes[i].imshow(face_image)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# Turn off any unused axes\n",
        "for j in range(i + 1, 20):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpBs_cYnaj4w"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from PIL import Image as PILImage\n",
        "import io\n",
        "import gc\n",
        "\n",
        "# Global variables to hold widgets\n",
        "face_widgets = []\n",
        "selection_buttons = []\n",
        "\n",
        "thumb_size = 150\n",
        "\n",
        "def load_and_display_faces(file_paths, positions):\n",
        "    global face_widgets, selection_buttons\n",
        "\n",
        "    # face_widgets.clear()\n",
        "    # selection_buttons.clear()\n",
        "\n",
        "    # for widget in face_widgets + selection_buttons:\n",
        "    #     widget.close()\n",
        "    face_widgets.clear()\n",
        "    selection_buttons.clear()\n",
        "\n",
        "    for i, (file_path, (top, right, bottom, left)) in enumerate(zip(file_paths, positions)):\n",
        "        image = PILImage.open(file_path).convert('RGB')\n",
        "        face = image.crop((left, top, right, bottom))\n",
        "        face = face.resize((thumb_size, thumb_size), PILImage.LANCZOS)\n",
        "\n",
        "        with io.BytesIO() as output:\n",
        "            face.save(output, format=\"JPEG\")\n",
        "            face_bytes = output.getvalue()\n",
        "\n",
        "        img_widget = widgets.Image(value=face_bytes, format='jpeg', width=thumb_size, height=thumb_size)\n",
        "        face_widgets.append(img_widget)\n",
        "\n",
        "        button = widgets.ToggleButton(description=str(i), value=False, icon='check')\n",
        "        selection_buttons.append(button)\n",
        "\n",
        "    return face_widgets, selection_buttons\n",
        "\n",
        "def get_unlabeled_sample():\n",
        "    unlabeled_df = df[df['label'].isnull()]\n",
        "    sample_size = min(len(unlabeled_df), 24)\n",
        "    return unlabeled_df.sample(sample_size)\n",
        "\n",
        "def update_display(new_sample_df):\n",
        "    global grid_layout\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    file_paths = new_sample_df['file_path'].tolist()\n",
        "    positions = new_sample_df['position'].tolist()\n",
        "    face_widgets, selection_buttons = load_and_display_faces(file_paths, positions)\n",
        "\n",
        "    for i in range(len(face_widgets)):\n",
        "        # Get the VBox at the specific grid position and update its children\n",
        "        grid_layout[i // 8, i % 8].children = [face_widgets[i], selection_buttons[i]]\n",
        "\n",
        "def on_submit_clicked(b):\n",
        "    global sample_df\n",
        "\n",
        "    gc.collect()\n",
        "    selected_indices = [int(button.description) for button in selection_buttons if button.value]\n",
        "\n",
        "    if selected_indices:\n",
        "        selected_df_indices = sample_df.iloc[selected_indices].index\n",
        "\n",
        "        for idx in selected_df_indices:\n",
        "            # Set the label for the current face\n",
        "            df.loc[idx, 'label'] = name_text.value\n",
        "\n",
        "            # Retrieve the encoding of the selected face\n",
        "            face_encoding = embeddings[df.loc[idx, 'encoding_index']]\n",
        "\n",
        "            # Compare with known face encodings\n",
        "            matches = face_recognition.compare_faces(embeddings,\n",
        "                                                     face_encoding,\n",
        "                                                     tolerance=0.4) # strict\n",
        "\n",
        "            # Update the label for all matching faces\n",
        "            for match_idx, is_match in enumerate(matches):\n",
        "                if is_match:\n",
        "                    df.loc[df['encoding_index'] == match_idx, 'label'] = name_text.value\n",
        "\n",
        "        # print(\"Set the label for\", match_count, \"images to\", name_text.value)\n",
        "\n",
        "    for button in selection_buttons:\n",
        "        button.value = False\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    sample_df = get_unlabeled_sample()\n",
        "    update_display(sample_df)\n",
        "\n",
        "def on_enter_pressed(_):\n",
        "    on_submit_clicked(None)\n",
        "\n",
        "# Create grid layout and controls layout placeholders\n",
        "grid_layout = widgets.GridspecLayout(3, 8)\n",
        "controls_layout = widgets.HBox(layout=widgets.Layout(justify_content='center'))\n",
        "\n",
        "# Initialize with first batch of images\n",
        "sample_df = get_unlabeled_sample()\n",
        "file_paths = sample_df['file_path'].tolist()\n",
        "positions = sample_df['position'].tolist()\n",
        "face_widgets, selection_buttons = load_and_display_faces(file_paths, positions)\n",
        "\n",
        "for i in range(len(face_widgets)):\n",
        "    box = widgets.VBox([face_widgets[i], selection_buttons[i]], layout=widgets.Layout(margin='0 0 10px 0'))\n",
        "    grid_layout[i // 8, i % 8] = box\n",
        "\n",
        "# Set up the Text and Button widgets\n",
        "name_text = widgets.Text(description=\"Name:\")\n",
        "name_text.on_submit(on_enter_pressed)\n",
        "submit_button = widgets.Button(description=\"Submit\")\n",
        "submit_button.on_click(on_submit_clicked)\n",
        "\n",
        "controls_layout.children = [name_text, submit_button]\n",
        "\n",
        "# Display the initial UI\n",
        "display(grid_layout)\n",
        "display(controls_layout)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45oONPkZ-8aX"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each label and sort them in descending order\n",
        "label_counts = df['label'].value_counts().sort_values(ascending=False)\n",
        "\n",
        "status = \"\"\n",
        "for label, count in label_counts.items():\n",
        "  status += label + \" \" + str(count) + \", \"\n",
        "if len(status) > 2:\n",
        "  status = status[:-2]\n",
        "print(status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaI-GpjkFpwP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def show_images(selected_label):\n",
        "\n",
        "  # Filter the DataFrame for the selected label\n",
        "  selected_df = df[df['label'] == selected_label]\n",
        "\n",
        "  # Extract file paths and positions\n",
        "  file_paths = selected_df['file_path'].tolist()\n",
        "  positions = selected_df['position'].tolist()\n",
        "\n",
        "  # Number of images and setting up grid dimensions\n",
        "  num_images = len(file_paths)\n",
        "  num_cols = 4\n",
        "  num_rows = (num_images + num_cols - 1) // num_cols  # Calculate the required number of rows\n",
        "\n",
        "  # Create the figure with subplots\n",
        "  fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, num_rows * 2.5))\n",
        "  axes = axes.flatten()\n",
        "\n",
        "  for i, (file_path, (top, right, bottom, left)) in enumerate(zip(file_paths, positions)):\n",
        "      # print(file_path)\n",
        "      image = Image.open(file_path).convert('RGB')\n",
        "\n",
        "      # Crop the image to the face region\n",
        "      face_region = (left, top, right, bottom)\n",
        "      face = image.crop(face_region)\n",
        "\n",
        "      # Resize the face to 100x100\n",
        "      face_resized = face.resize((100, 100), Image.LANCZOS)\n",
        "\n",
        "      axes[i].imshow(face_resized)\n",
        "      axes[i].axis('off')\n",
        "\n",
        "  # Turn off axes for any empty subplots\n",
        "  for j in range(i + 1, num_cols * num_rows):\n",
        "      axes[j].axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "1tJT4ww757fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_set_by_user = [\"Rob\", \"Jen\"]\n",
        "avg_encodings = {}\n",
        "\n",
        "for label in labels_set_by_user:\n",
        "    label_encodings = embeddings[df['label'] == label]\n",
        "    avg_encodings[label] = np.mean(label_encodings, axis=0)\n",
        "\n",
        "def find_match(encoding, avg_encodings, threshold=0.6):\n",
        "    for label, avg_encoding in avg_encodings.items():\n",
        "        if face_recognition.face_distance([avg_encoding], encoding)[0] < threshold:\n",
        "            return label\n",
        "    return None\n",
        "\n",
        "df['predicted_label'] = None  # Initialize the column\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    current_encoding = embeddings[row['encoding_index']]\n",
        "    predicted_label = find_match(current_encoding, avg_encodings)\n",
        "\n",
        "    if predicted_label is not None:\n",
        "        df.at[index, 'predicted_label'] = predicted_label"
      ],
      "metadata": {
        "id": "hkd5uWxs7MZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "MTi5sb6LAIuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_images_with_all_labels(labels):\n",
        "    # Create a DataFrame to hold file_paths that contain all labels\n",
        "    valid_file_paths = pd.DataFrame(columns=['file_path'])\n",
        "\n",
        "    # Get unique file_paths\n",
        "    unique_file_paths = df['file_path'].unique()\n",
        "\n",
        "    # Iterate through each file_path\n",
        "    for file_path in unique_file_paths:\n",
        "        # Get all rows for the current file_path\n",
        "        rows = df[df['file_path'] == file_path]\n",
        "        # Check if all specified labels are present in these rows\n",
        "        if all(label in rows['predicted_label'].values for label in labels):\n",
        "            # Add the file_path to the valid_file_paths DataFrame\n",
        "            valid_file_paths = valid_file_paths.append({'file_path': file_path}, ignore_index=True)\n",
        "\n",
        "    return valid_file_paths\n",
        "\n",
        "labels_to_check = ['Rob', 'Jen']\n",
        "valid_paths_df = find_images_with_all_labels(labels_to_check)\n",
        "\n",
        "# Now you can use valid_paths_df to process images that contain all specified labels\n",
        "valid_paths_df"
      ],
      "metadata": {
        "id": "Pg61aSdV8qCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_paths_df"
      ],
      "metadata": {
        "id": "Zv5CJ3hcCq1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def show_valid_images(valid_paths_df):\n",
        "    # Extract file paths\n",
        "    file_paths = valid_paths_df['file_path'].tolist()\n",
        "\n",
        "    # Number of images and setting up grid dimensions\n",
        "    num_images = len(file_paths)\n",
        "    if num_images == 0:\n",
        "        print(\"No valid images to display.\")\n",
        "        return\n",
        "\n",
        "    num_cols = 4\n",
        "    num_rows = (num_images + num_cols - 1) // num_cols  # Calculate the required number of rows\n",
        "\n",
        "    # Create the figure with subplots\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, num_rows * 2.5))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, file_path in enumerate(file_paths):\n",
        "        # Load the image\n",
        "        image = Image.open(file_path).convert('RGB')\n",
        "\n",
        "        # Display the image\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Turn off axes for any empty subplots\n",
        "    for j in range(i + 1, num_cols * num_rows):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with the dataframe of valid paths\n",
        "show_valid_images(valid_paths_df)\n"
      ],
      "metadata": {
        "id": "kKDQgSEGCVKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: convert valid_paths_df to a list\n",
        "\n",
        "valid_paths_list = valid_paths_df['file_path'].tolist()\n",
        "print(valid_paths_list)\n"
      ],
      "metadata": {
        "id": "Kn40dg9UKeKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}